# -*- coding: utf-8 -*-
"""DM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNtK22TrvFwtxjoie8iKG8ZMlK5Q8GJ_
"""

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler
import os

# Kiểm tra sự tồn tại của file trước khi đọc
train_path = "/content/train.csv"
test_path = "/content/test.csv"

if not os.path.isfile(train_path):
    raise FileNotFoundError(f"Tệp {train_path} không tồn tại hoặc không hợp lệ. Vui lòng kiểm tra đường dẫn và tải lên tệp đúng.")
if not os.path.isfile(test_path):
    raise FileNotFoundError(f"Tệp {test_path} không tồn tại hoặc không hợp lệ. Vui lòng kiểm tra đường dẫn và tải lên tệp đúng.")

# Đọc dữ liệu
try:
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)
except pd.errors.EmptyDataError:
    raise ValueError("Tệp CSV trống hoặc không có dữ liệu hợp lệ.")
except pd.errors.ParserError:
    raise ValueError("Lỗi định dạng trong tệp CSV. Kiểm tra dữ liệu đầu vào.")
except Exception as e:
    raise ValueError(f"Lỗi không xác định khi đọc tệp CSV: {e}")

# Xác định các cột chung giữa train và test
common_cols = train_df.columns.intersection(test_df.columns).tolist()
if not common_cols:
    raise ValueError("Không có cột chung nào giữa train.csv và test.csv. Kiểm tra dữ liệu đầu vào.")

# Lưu danh sách các cột có kiểu dữ liệu số và kiểu phân loại
num_cols = train_df[common_cols].select_dtypes(include=["number"]).columns.tolist()
cat_cols = train_df[common_cols].select_dtypes(include=["object"]).columns.tolist()

# Xử lý giá trị thiếu
if num_cols:
    num_imputer = SimpleImputer(strategy='median')
    train_df[num_cols] = num_imputer.fit_transform(train_df[num_cols])
    test_df[num_cols] = num_imputer.transform(test_df[num_cols])

if cat_cols:
    cat_imputer = SimpleImputer(strategy='most_frequent')
    train_df[cat_cols] = cat_imputer.fit_transform(train_df[cat_cols])
    test_df[cat_cols] = cat_imputer.transform(test_df[cat_cols])

# Loại bỏ ngoại lai (giá bất thường)
if 'SalePrice' in train_df.columns:
    q1, q3 = train_df['SalePrice'].quantile([0.05, 0.95])
    train_df = train_df[(train_df['SalePrice'] >= q1) & (train_df['SalePrice'] <= q3)]

# Chuyển đổi đơn vị
if 'SalePrice' in train_df.columns:
    train_df['SalePrice'] = train_df['SalePrice'] / 1_000_000  # Chuyển thành triệu VNĐ
if 'LotArea' in train_df.columns and 'LotArea' in test_df.columns:
    train_df['LotArea'] = train_df['LotArea'] / 10.764  # Chuyển thành m²
    test_df['LotArea'] = test_df['LotArea'] / 10.764

# Mã hóa One-Hot Encoding
encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # Thay thế 'sparse' bằng 'sparse_output'
encoded_train = encoder.fit_transform(train_df[cat_cols])
encoded_test = encoder.transform(test_df[cat_cols])

ohe_columns = encoder.get_feature_names_out(cat_cols)
train_ohe_df = pd.DataFrame(encoded_train, columns=ohe_columns)
test_ohe_df = pd.DataFrame(encoded_test, columns=ohe_columns)

train_df = train_df.drop(columns=cat_cols).reset_index(drop=True)
test_df = test_df.drop(columns=cat_cols).reset_index(drop=True)

train_df = pd.concat([train_df, train_ohe_df], axis=1)
test_df = pd.concat([test_df, test_ohe_df], axis=1)

# Chuẩn hóa dữ liệu số
scaler = MinMaxScaler()
train_df[num_cols] = scaler.fit_transform(train_df[num_cols])
test_df[num_cols] = scaler.transform(test_df[num_cols])

# Tạo đặc trưng mới
if 'Population' in train_df.columns and 'LotArea' in train_df.columns:
    train_df['Density'] = train_df['Population'] / train_df['LotArea']
    test_df['Density'] = test_df['Population'] / test_df['LotArea']

if 'DistanceToCenter' in train_df.columns:
    train_df['DistanceToCenter'] = train_df['DistanceToCenter'] / 1000  # Đổi thành km
    test_df['DistanceToCenter'] = test_df['DistanceToCenter'] / 1000

# Lưu dữ liệu đã xử lý
train_cleaned_path = "/mnt/data/train_cleaned.csv"
test_cleaned_path = "/mnt/data/test_cleaned.csv"

# Create the directory if it doesn't exist
os.makedirs(os.path.dirname(train_cleaned_path), exist_ok=True)

train_df.to_csv(train_cleaned_path, index=False)
test_df.to_csv(test_cleaned_path, index=False)

print("Hoàn thành xử lý dữ liệu.")